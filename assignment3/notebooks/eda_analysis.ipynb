{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for California Housing Dataset\n",
    "\n",
    "This notebook performs comprehensive EDA on the California Housing dataset to understand patterns, relationships, and prepare for linear regression modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import custom modules\n",
    "from data_cleaning import load_data, handle_missing_values, remove_outliers, feature_engineering\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load and preprocess data\n",
    "df = load_data('../data/housing.csv')\n",
    "df = handle_missing_values(df)\n",
    "numerical_cols = ['median_income', 'median_house_value', 'total_rooms', 'total_bedrooms']\n",
    "df = remove_outliers(df, numerical_cols)\n",
    "df = feature_engineering(df)\n",
    "\n",
    "print(f\"Dataset shape after preprocessing: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Univariate Analysis\n",
    "\n",
    "Let's examine the distribution of individual variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical variables analysis\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "target_col = 'median_house_value'\n",
    "\n",
    "print(\"Numerical Variables Summary:\")\n",
    "for col in numerical_cols:\n",
    "    if col != target_col:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Mean: {df[col].mean():.2f}\")\n",
    "        print(f\"  Median: {df[col].median():.2f}\")\n",
    "        print(f\"  Std: {df[col].std():.2f}\")\n",
    "        print(f\"  Skewness: {df[col].skew():.2f}\")\n",
    "\n",
    "# Histograms\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    if i < 8:\n",
    "        sns.histplot(df[col], kde=True, ax=axes[i])\n",
    "        axes[i].set_title(f'Distribution of {col}')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bivariate Analysis\n",
    "\n",
    "Let's examine relationships between features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Correlation with target\n",
    "correlations = df[numerical_cols].corr()[target_col].sort_values(ascending=False)\n",
    "print(\"\\nCorrelation with target variable:\")\n",
    "print(correlations)\n",
    "\n",
    "# Scatter plots with target\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "top_features = correlations.index[1:7]  # Exclude target itself\n",
    "\n",
    "for i, col in enumerate(top_features):\n",
    "    sns.scatterplot(x=df[col], y=df[target_col], ax=axes[i], alpha=0.6)\n",
    "    axes[i].set_title(f'{col} vs {target_col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multicollinearity Check\n",
    "\n",
    "Check for multicollinearity using Variance Inflation Factor (VIF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate VIF\n",
    "def calculate_vif(df, features):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = features\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df[features].values, i) \n",
    "                        for i in range(len(features))]\n",
    "    return vif_data\n",
    "\n",
    "# Features for VIF calculation (excluding target)\n",
    "features_for_vif = [col for col in numerical_cols if col != target_col]\n",
    "vif_data = calculate_vif(df, features_for_vif)\n",
    "\n",
    "print(\"Variance Inflation Factor (VIF) Analysis:\")\n",
    "print(vif_data.sort_values('VIF', ascending=False))\n",
    "\n",
    "# Highlight high VIF features\n",
    "high_vif = vif_data[vif_data['VIF'] > 5]\n",
    "if not high_vif.empty:\n",
    "    print(\"\\nFeatures with high multicollinearity (VIF > 5):\")\n",
    "    print(high_vif)\n",
    "else:\n",
    "    print(\"\\nNo features with high multicollinearity detected.\")\n",
    "\n",
    "# VIF visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='VIF', y='Feature', data=vif_data.sort_values('VIF', ascending=False))\n",
    "plt.axvline(x=5, color='red', linestyle='--', label='VIF = 5 threshold')\n",
    "plt.title('Variance Inflation Factor (VIF) by Feature')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Importance\n",
    "\n",
    "Visualize the most important features based on correlation with target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance based on correlation\n",
    "plt.figure(figsize=(10, 6))\n",
    "feature_importance = correlations.abs().sort_values(ascending=False)[1:11]  # Top 10 features\n",
    "sns.barplot(x=feature_importance.values, y=feature_importance.index)\n",
    "plt.title('Top 10 Features by Correlation with Median House Value')\n",
    "plt.xlabel('Absolute Correlation')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 most correlated features with target:\")\n",
    "for i, (feature, corr) in enumerate(correlations.items()):\n",
    "    if i > 0 and i <= 5:  # Skip target itself\n",
    "        print(f\"{i}. {feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Insights\n",
    "\n",
    "Key findings from the EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== EDA Summary ===\")\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"- Total samples: {len(df)}\")\n",
    "print(f\"- Number of features: {len(df.columns) - 1}\")  # Excluding target\n",
    "print(f\"- Target variable: {target_col}\")\n",
    "\n",
    "print(f\"\\nKey Correlations:\")\n",
    "top_corr = correlations.head()\n",
    "for feature, corr in top_corr.items():\n",
    "    print(f\"- {feature}: {corr:.3f}\")\n",
    "\n",
    "print(f\"\\nMulticollinearity Issues:\")\n",
    "if not high_vif.empty:\n",
    "    print(f\"- {len(high_vif)} features have VIF > 5\")\n",
    "    print(f\"- Highest VIF: {high_vif['Feature'].iloc[0]} ({high_vif['VIF'].iloc[0]:.2f})\")\n",
    "else:\n",
    "    print(\"- No significant multicollinearity detected\")\n",
    "\n",
    "print(f\"\\nRecommendations for Modeling:\")\n",
    "print(\"- Focus on features with strong correlation to target\")\n",
    "print(\"- Consider feature selection to reduce multicollinearity\")\n",
    "print(\"- Apply feature scaling before linear regression\")\n",
    "print(\"- Consider polynomial features or interaction terms if needed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
